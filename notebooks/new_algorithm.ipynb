{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "CompareSearchModel.forward() missing 1 required positional argument: 'semantic_features'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Maods\\Documents\\Development\\Mestrado\\terumo\\apps\\renal-pathology-retrieval\\notebooks\\new_algorithm.ipynb Cell 1\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Maods/Documents/Development/Mestrado/terumo/apps/renal-pathology-retrieval/notebooks/new_algorithm.ipynb#W0sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m num_epochs \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Maods/Documents/Development/Mestrado/terumo/apps/renal-pathology-retrieval/notebooks/new_algorithm.ipynb#W0sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Maods/Documents/Development/Mestrado/terumo/apps/renal-pathology-retrieval/notebooks/new_algorithm.ipynb#W0sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m     outputs \u001b[39m=\u001b[39m model(X)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Maods/Documents/Development/Mestrado/terumo/apps/renal-pathology-retrieval/notebooks/new_algorithm.ipynb#W0sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m     loss \u001b[39m=\u001b[39m criterion(outputs, y)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Maods/Documents/Development/Mestrado/terumo/apps/renal-pathology-retrieval/notebooks/new_algorithm.ipynb#W0sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\Users\\Maods\\.virtualenvs\\renal-pathology-retrieval-P_udDvkW\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;31mTypeError\u001b[0m: CompareSearchModel.forward() missing 1 required positional argument: 'semantic_features'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "X = np.random.rand(100, 1)\n",
    "y = 2 * X + 1 + 0.1 * np.random.randn(100, 1)\n",
    "\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "class Config():\n",
    "    def __init__(self):\n",
    "        self.embed_dim = 128\n",
    "        self.num_heads = 128\n",
    "        self.head_dim = 128\n",
    "        self.hidden_size = 128\n",
    "        self.input_size = 128\n",
    "        self.output_size = 1\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()  \n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)  \n",
    "        # self.sigmoid = nn.Sigmoid()  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        # x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class CompareSearchModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super(CompareSearchModel, self).__init__()\n",
    "\n",
    "        self.num_heads = cfg.num_heads\n",
    "        self.head_dim = cfg.head_dim\n",
    "        self.mha = nn.MultiheadAttention(cfg.embed_dim, cfg.num_heads)\n",
    "        self.mlp = MLP(cfg.input_size, cfg.hidden_size, cfg.output_size)\n",
    "\n",
    "\n",
    "    def forward(self, embed_image, semantic_features):\n",
    "\n",
    "        flattened_embed = embed_image.view(embed_image.size(0), -1)\n",
    "        concatenated_features = torch.cat((flattened_embed, semantic_features), dim=1)\n",
    "        x = concatenated_features.view(concatenated_features.shape[0], -1, self.num_heads, self.head_dim)\n",
    "        attn_output, _ = self.mha(x,x,x)\n",
    "        logits = self.mlp(x)\n",
    "\n",
    "        return logits\n",
    "\n",
    "\n",
    "cfg = Config()\n",
    "model = CompareSearchModel(cfg)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    outputs = model(X)\n",
    "    loss = criterion(outputs, y)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Época [{epoch + 1}/{num_epochs}], Perda: {loss.item():.4f}')\n",
    "\n",
    "print('Training Completed')\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_input = torch.tensor([[0.6]], dtype=torch.float32)\n",
    "    predicted_output = model(test_input)\n",
    "    print(f'Predição para entrada 0.6: {predicted_output.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "renal-pathology-retrieval-P_udDvkW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
