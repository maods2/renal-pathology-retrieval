{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletData(Dataset):\n",
    "    def __init__(self, path, transform):\n",
    "        self.path = path\n",
    "        self.categories_num = 6       \n",
    "        self.transform = transform\n",
    "        self.image_extensions = [\"jpg\", \"jpeg\", \"png\", \"gif\", \"bmp\", \"tiff\"]\n",
    "        self.class_mapping = {\n",
    "            1: \"crescentes\",\n",
    "            2: \"hipercellularity\",\n",
    "            3: \"membranous\",\n",
    "            4: \"normal\",\n",
    "            5: \"Podocitopatia\",\n",
    "            6: \"sclerosis\",\n",
    "        }\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # our positive class for the triplet\n",
    "        idx = idx%self.categories_num + 1\n",
    "\n",
    "        # choosing our pair of positive images (im1, im2)\n",
    "        positive_data_dir = Path(os.path.join(self.path, self.class_mapping[idx]))\n",
    "        positives = [file for file in positive_data_dir.glob('**/*') if file.suffix.lower()[1:] in self.image_extensions]\n",
    "        im1, im2 = random.sample(positives, 2)\n",
    "\n",
    "        # choosing a negative class and negative image (im3)\n",
    "        negative_categories = list(self.class_mapping.values())\n",
    "        negative_categories.remove(self.class_mapping[idx])\n",
    "        negative_category = str(random.choice(negative_categories))\n",
    "        negative_data_dir = Path(os.path.join(self.path, negative_category))\n",
    "        negatives = [file for file in negative_data_dir.glob('**/*') if file.suffix.lower()[1:] in self.image_extensions]\n",
    "        im3 = random.choice(negatives)\n",
    "\n",
    "        im1 = self.transform(Image.open(im1))\n",
    "        im2 = self.transform(Image.open(im2))\n",
    "        im3 = self.transform(Image.open(im3))\n",
    "\n",
    "        return [im1, im2, im3]\n",
    "\n",
    "    # we'll put some value that we want since there can be far too many triplets possible\n",
    "    # multiples of the number of images/ number of categories is a good choice\n",
    "    def __len__(self):\n",
    "        return self.categories_num*50\n",
    "\n",
    "\n",
    "\n",
    "class TripletLoss(nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        \n",
    "    def calc_euclidean(self, x1, x2):\n",
    "        return (x1 - x2).pow(2).sum(1)\n",
    "    \n",
    "    # Distances in embedding space is calculated in euclidean\n",
    "    def forward(self, anchor, positive, negative):\n",
    "        distance_positive = self.calc_euclidean(anchor, positive)\n",
    "        distance_negative = self.calc_euclidean(anchor, negative)\n",
    "        losses = torch.relu(distance_positive - distance_negative + self.margin)\n",
    "        return losses.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "source": [
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "model = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "# model._avg_pooling = Identity()\n",
    "# model._dropout = Identity()\n",
    "model._fc = Identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 225.2099609375\n",
      "Train Loss: 157.10498046875\n",
      "Train Loss: 84.47178649902344\n",
      "Train Loss: 55.5457878112793\n",
      "Train Loss: 41.929073333740234\n",
      "Train Loss: 32.78470230102539\n",
      "Train Loss: 27.710474014282227\n",
      "Train Loss: 25.589614868164062\n",
      "Train Loss: 20.47807502746582\n",
      "Train Loss: 20.723966598510742\n",
      "Train Loss: 21.62590789794922\n",
      "Train Loss: 17.63516616821289\n",
      "Train Loss: 17.389251708984375\n",
      "Train Loss: 16.75670051574707\n",
      "Train Loss: 16.653018951416016\n",
      "Train Loss: 17.93628692626953\n",
      "Train Loss: 15.407001495361328\n",
      "Train Loss: 16.676788330078125\n",
      "Train Loss: 16.034626007080078\n",
      "Train Loss: 13.864738464355469\n",
      "Train Loss: 13.505125045776367\n",
      "Train Loss: 14.332818984985352\n",
      "Train Loss: 15.217344284057617\n",
      "Train Loss: 13.774264335632324\n",
      "Train Loss: 14.844779968261719\n",
      "Train Loss: 15.75804615020752\n",
      "Train Loss: 14.27849292755127\n",
      "Train Loss: 14.023294448852539\n",
      "Train Loss: 12.201282501220703\n",
      "Train Loss: 12.542526245117188\n",
      "Train Loss: 10.421916007995605\n",
      "Train Loss: 13.3844575881958\n",
      "Train Loss: 16.12106704711914\n",
      "Train Loss: 11.130306243896484\n",
      "Train Loss: 15.24340534210205\n",
      "Train Loss: 13.829570770263672\n",
      "Train Loss: 11.984983444213867\n",
      "Train Loss: 12.145051956176758\n",
      "Train Loss: 13.94720458984375\n",
      "Train Loss: 11.941850662231445\n",
      "Train Loss: 10.871831893920898\n",
      "Train Loss: 13.712389945983887\n",
      "Train Loss: 9.4629487991333\n",
      "Train Loss: 13.1204833984375\n",
      "Train Loss: 11.858129501342773\n",
      "Train Loss: 12.03175163269043\n",
      "Train Loss: 13.664875030517578\n",
      "Train Loss: 9.986474990844727\n",
      "Train Loss: 13.76466178894043\n",
      "Train Loss: 11.753847122192383\n",
      "Train Loss: 10.433895111083984\n",
      "Train Loss: 9.945638656616211\n",
      "Train Loss: 12.36178970336914\n",
      "Train Loss: 9.927720069885254\n",
      "Train Loss: 11.305320739746094\n",
      "Train Loss: 11.502890586853027\n",
      "Train Loss: 10.919471740722656\n",
      "Train Loss: 13.626548767089844\n",
      "Train Loss: 9.775053977966309\n",
      "Train Loss: 11.495925903320312\n",
      "Train Loss: 10.88148307800293\n",
      "Train Loss: 10.721665382385254\n",
      "Train Loss: 10.091638565063477\n",
      "Train Loss: 10.355603218078613\n",
      "Train Loss: 9.326482772827148\n",
      "Train Loss: 8.736640930175781\n",
      "Train Loss: 10.222418785095215\n",
      "Train Loss: 11.293519973754883\n",
      "Train Loss: 10.933503150939941\n",
      "Train Loss: 10.389347076416016\n",
      "Train Loss: 13.206191062927246\n",
      "Train Loss: 10.754042625427246\n",
      "Train Loss: 10.744292259216309\n",
      "Train Loss: 9.2446870803833\n",
      "Train Loss: 10.974259376525879\n",
      "Train Loss: 12.510026931762695\n",
      "Train Loss: 10.255855560302734\n",
      "Train Loss: 10.514411926269531\n",
      "Train Loss: 9.66835880279541\n",
      "Train Loss: 9.945710182189941\n",
      "Train Loss: 10.780843734741211\n",
      "Train Loss: 11.557064056396484\n",
      "Train Loss: 8.618797302246094\n",
      "Train Loss: 8.960213661193848\n",
      "Train Loss: 9.311844825744629\n",
      "Train Loss: 10.027813911437988\n",
      "Train Loss: 9.297245025634766\n",
      "Train Loss: 9.642111778259277\n",
      "Train Loss: 8.379377365112305\n",
      "Train Loss: 10.099382400512695\n",
      "Train Loss: 9.884451866149902\n",
      "Train Loss: 6.205371379852295\n",
      "Train Loss: 8.986865043640137\n",
      "Train Loss: 9.116732597351074\n",
      "Train Loss: 10.460199356079102\n",
      "Train Loss: 8.222259521484375\n",
      "Train Loss: 8.552046775817871\n",
      "Train Loss: 8.39543628692627\n",
      "Train Loss: 9.974703788757324\n",
      "Train Loss: 9.139171600341797\n"
     ]
    }
   ],
   "source": [
    "path= \"C:/Users/Maods/Documents/Development/Mestrado/terumo/apps/renal-pathology-retrieval/data/02_data_split/train_data/\"\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "train_data = TripletData(path, transform)\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_data, batch_size=20, shuffle=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "epochs = 100 \n",
    "# Our base model\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "triplet_loss = TripletLoss()\n",
    "train_loss = []\n",
    "\n",
    "# Training\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    cont =0\n",
    "    for data in train_loader:\n",
    "        cont=cont+1\n",
    "        optimizer.zero_grad()\n",
    "        x1,x2,x3 = data\n",
    "        e1 = model(x1.to(device))\n",
    "        e2 = model(x2.to(device))\n",
    "        e3 = model(x3.to(device)) \n",
    "        \n",
    "        loss = triplet_loss(e1,e2,e3)\n",
    "        epoch_loss += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "    train_loss.append(epoch_loss.item())\n",
    "\n",
    "    print(\"Train Loss: {}\".format(epoch_loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Maods\\Documents\\Development\\Mestrado\\terumo\\apps\\renal-pathology-retrieval\\notebooks\\triplet_training.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Maods/Documents/Development/Mestrado/terumo/apps/renal-pathology-retrieval/notebooks/triplet_training.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Maods/Documents/Development/Mestrado/terumo/apps/renal-pathology-retrieval/notebooks/triplet_training.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(train_loss);\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_loss' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_loss);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'faiss'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Maods\\Documents\\Development\\Mestrado\\terumo\\apps\\renal-pathology-retrieval\\notebooks\\triplet_training.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Maods/Documents/Development/Mestrado/terumo/apps/renal-pathology-retrieval/notebooks/triplet_training.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mfaiss\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'faiss'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "renal-pathology-retrieval-P_udDvkW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
