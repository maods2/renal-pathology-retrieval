{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import sys\n",
    "\n",
    "sys.path.append('../embeddings/')\n",
    "sys.path.append('./embeddings/')\n",
    "sys.path.append('C:/Users/Maods/Downloads/terumo-seg-esclerose-main/terumo-seg-esclerose-main/terumo_seg_esclerose/')\n",
    "sys.path.append('C:/Users/Maods/Downloads/terumo-seg-esclerose-main/terumo-seg-esclerose-main/terumo_seg_esclerose/utils')\n",
    "sys.path.append('..')\n",
    "\n",
    "from dataset import ImageDataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "from utils import slice_image_paths\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import torch\n",
    "import torchvision\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import numpy as np\n",
    "import re\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n",
    "# from terumo_seg_esclerose.cli import run_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install C:/Users/Maods/Downloads/terumo-seg-esclerose-main/terumo-seg-esclerose-main/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Maods\\.pyenv\\pyenv-win\\versions\\3.10.4\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Config (path: C:/Users/Maods/Downloads/terumo-seg-esclerose-main/terumo-seg-esclerose-main/configs/tiny/tiny-efficientnetb0-unet-pipeline.py): {'dataset_name': 'hubmap', 'path': './dist/datasets/hubmap/', 'cache': True, 'batch_size': 8, 'multiplier_bin': 4, 'binned_max': 20, 'output_pre': './dist/datasets/hubmap/patch/', 'split': 'train', 'dataset_pre_processing': {'shift_list': [0, 512], 'tile_size': 1024}, 'train_param': {'type': 'train_param', 'output_path': './dist/pretraining/', 'data_csv_path': './dist/datasets/hubmap/patch/data_balanced.csv', 'test_size': 0.3, 'random_state': 19, 'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225], 'batch_size': 12, 'shuffle': True, 'encoder_name': 'efficientnet-b0', 'encoder_weights': 'imagenet', 'classes': 1, 'activation': None, 'network_name': 'unet', 'loop_param': {'type': 'loop_param', 'filename_checkpoint': 'best_checkpoint.pth', 'cache_weight': None, 'result_csv': 'history.csv', 'max_lr': 0.001, 'epochs': 50, 'weight_decay': 1e-05, 'criterion_name': 'bce'}, 'transform_param': {'type': 'transform_param', 'img_size': 320}}, 'test_param': {'model_param': {'output_exp': {'sclerosis': 'C:/Users/Maods/Downloads/terumo-seg-esclerose-main/terumo-seg-esclerose-main/checkpoint/sclerosis', 'glomerulus': 'C:/Users/Maods/Downloads/terumo-seg-esclerose-main/terumo-seg-esclerose-main/checkpoint/glomerulus'}, 'filename_checkpoint': 'epoch_50.pth', 'encoder_name': 'efficientnet-b0', 'encoder_weights': 'imagenet', 'classes': 1, 'activation': None, 'network_name': 'unet'}, 'model': 'unet', 'input_resolution': 320, 'resolution': 1024, 'pad_size': 0, 'clf_threshold': 0.5, 'small_mask_threshold': 0, 'mask_threshold': 0.5, 'tta': 3, 'test_batch_size': 12, 'num_workers': 4}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import typer\n",
    "from terumo_seg_esclerose.utils.config import ConfigLoaded\n",
    "\n",
    "from terumo_seg_esclerose.predict.seg_glomerulus import (\n",
    "    predict as predict_glo,\n",
    "    get_model_list as get_model_list_glo\n",
    "    )\n",
    "from terumo_seg_esclerose.predict.seg_sclerosis import( \n",
    "    predict as predict_sle,\n",
    "    get_model_list as get_model_list_sle,\n",
    "    )\n",
    "from mmengine.config import Config\n",
    "import numpy as np\n",
    "app = typer.Typer()\n",
    "\n",
    "path = 'C:/Users/Maods/Downloads/terumo-seg-esclerose-main/terumo-seg-esclerose-main/configs/tiny/tiny-efficientnetb0-unet-pipeline.py'\n",
    "ConfigLoaded().load_config(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_weights(model, model_path,device):\n",
    "    checkpoint = torch.load(model_path,map_location=torch.device(device))\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    return model\n",
    "\n",
    "def get_all_image_files(pathlib_root_folder):\n",
    "    img_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.gif']\n",
    "    img_regex = re.compile('|'.join(img_extensions), re.IGNORECASE)\n",
    "    image_files = [f for f in pathlib_root_folder.glob('**/*') if f.is_file() and img_regex.search(f.suffix)]\n",
    "    return image_files\n",
    "\n",
    "\n",
    "def predict(model, image):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        output = model(image.to(device))\n",
    "        scores = torch.sigmoid(output)\n",
    "        predictions = (scores>0.5).float()\n",
    "        _, pred = torch.min(predictions, 1)\n",
    "\n",
    "    return pred.item()\n",
    "\n",
    "def sclerosis_predict(image_path, model_list_glo, model_list_sle):\n",
    "    mask_glo = predict_glo(image_path, model_list_glo)\n",
    "    mask_sle = predict_sle(image_path, model_list_sle)\n",
    "\n",
    "    inter = np.logical_and(mask_glo > 0.5, mask_sle > 0.5)\n",
    "    p = np.sum(inter) / (np.sum(mask_glo > 0.5) + 0.00001)\n",
    "\n",
    "    # print(f\"Glomerulu with {p} sclerosis\")\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maods/.cache\\torch\\hub\\checkpoints\n",
      "Loads checkpoint by local backend from path: C:/Users/Maods/Downloads/terumo-seg-esclerose-main/terumo-seg-esclerose-main/checkpoint/glomerulus/epoch_50.pth\n",
      "C:\\Users\\Maods/.cache\\torch\\hub\\checkpoints\n",
      "Loads checkpoint by local backend from path: C:/Users/Maods/Downloads/terumo-seg-esclerose-main/terumo-seg-esclerose-main/checkpoint/sclerosis/epoch_50.pth\n"
     ]
    }
   ],
   "source": [
    "model_list_glo = get_model_list_glo()\n",
    "model_list_sle = get_model_list_sle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, net_version, num_classes, freeze: bool = False):\n",
    "        super(Net, self).__init__()\n",
    "        self.backbone = EfficientNet.from_pretrained('efficientnet-'+net_version)\n",
    "        self.backbone._fc = nn.Sequential(\n",
    "            nn.Linear(1280, num_classes),\n",
    "        )\n",
    "        if freeze:\n",
    "            # freeze backbone layers\n",
    "            for name, param in self.backbone.named_parameters():\n",
    "                if not name.startswith(\"_fc\"):\n",
    "                    param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maods/.cache\\torch\\hub\\checkpoints\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "C:\\Users\\Maods/.cache\\torch\\hub\\checkpoints\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "C:\\Users\\Maods/.cache\\torch\\hub\\checkpoints\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "C:\\Users\\Maods/.cache\\torch\\hub\\checkpoints\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "C:\\Users\\Maods/.cache\\torch\\hub\\checkpoints\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "C:\\Users\\Maods/.cache\\torch\\hub\\checkpoints\n",
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "source": [
    "hiper_path = './Hypercellularity-2024-02-10 21_19_55.851047-3_fold_min_loss_checkpoint.pth.tar'\n",
    "membran_path = './Membranous-2024-02-10 21_20_09.125156-1_fold_min_loss_checkpoint.pth.tar'\n",
    "sclero_path = './Sclerosis-2024-02-10 21_20_15.760971-3_fold_min_loss_checkpoint.pth.tar'\n",
    "normal_path = './Normal-2024-02-10 21_20_02.347231-2_fold_min_loss_checkpoint.pth.tar'\n",
    "podoc_path = './Podocytopathy-2024-02-10 21_20_29.072759-2_fold_min_loss_checkpoint.pth.tar'\n",
    "cresc_path = './Crescent-2024-02-10 21_20_22.470548-1_fold_min_loss_checkpoint.pth.tar'\n",
    "\n",
    "\n",
    "hiper_model = load_model_weights(Net(net_version=\"b0\", num_classes=2).to(device), hiper_path,device)\n",
    "membran_model = load_model_weights(Net(net_version=\"b0\", num_classes=2).to(device), membran_path,device)\n",
    "sclero_model = load_model_weights(Net(net_version=\"b0\", num_classes=2).to(device), sclero_path,device)\n",
    "normal_model = load_model_weights(Net(net_version=\"b0\", num_classes=2).to(device), normal_path,device)\n",
    "podoc_model = load_model_weights(Net(net_version=\"b0\", num_classes=2).to(device), podoc_path,device)\n",
    "cresc_model = load_model_weights(Net(net_version=\"b0\", num_classes=2).to(device), cresc_path,device)\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "\n",
    "\n",
    "models = [hiper_model,membran_model,sclero_model,normal_model,podoc_model,cresc_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# image = Image.open('C:/Users/Maods/Documents/Development/Mestrado/terumo/apps/terumo-model-binary-glomerulus-hypercellularity/data/raw/hipercellularity/AZAN/PSHIPERCELULARIDADE20200802-10.JPG')\n",
    "# image = Image.open('C:/Users/Maods/Documents/Development/Mestrado/terumo/apps/terumo-model-binary-glomerulus-hypercellularity/data/raw/crescentes/H_E/FIOCRUZ20190122 (6).jpg')\n",
    "# image = transform(image)\n",
    "# image = image.unsqueeze(0)\n",
    "# with torch.no_grad():\n",
    "#     cresc_model.eval()\n",
    "#     output = cresc_model(image.to(device))\n",
    "#     scores = torch.sigmoid(output)\n",
    "# scores[:, 0]\n",
    "# predictions = (scores>0.5).float()\n",
    "# predictions,\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Maods\\.pyenv\\pyenv-win\\versions\\3.10.4\\lib\\site-packages\\rasterio\\__init__.py:317: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "data = ImageDataLoader('../data/02_data_split/train_data')\n",
    "dataloader = DataLoader(data.dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "target = []\n",
    "paths = []\n",
    "labels = []\n",
    "num_att = 7\n",
    "feature_embeddings = np.empty((0, num_att))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i, (x, y, path, label) in enumerate(dataloader):\n",
    "    x = x.to(device=device)\n",
    "    with torch.no_grad():\n",
    "        prediction_columns = []\n",
    "        for model in models:\n",
    "            model.eval()\n",
    "            output = model(x)\n",
    "            scores = torch.sigmoid(output)\n",
    "            prediction_columns.append(scores[:, 0].view(-1, 1))\n",
    "\n",
    "    prediction_matrix = torch.cat(prediction_columns, dim=1)\n",
    "\n",
    "    sclerosis_batch = np.array([sclerosis_predict(\n",
    "                                            p,\n",
    "                                            model_list_glo,\n",
    "                                            model_list_sle\n",
    "                                                  ) for p in path]).reshape(-1,1)     \n",
    "    emb_batch = np.hstack(( prediction_matrix.cpu().detach().numpy(), sclerosis_batch))\n",
    "    feature_embeddings = np.vstack((feature_embeddings, emb_batch))\n",
    "    target.extend(list(y.cpu().detach().numpy()))\n",
    "    paths.extend(slice_image_paths(path))\n",
    "    labels.extend(label)\n",
    "\n",
    "\n",
    "data_dict = {\n",
    "    \"model\": 'semantic_att',\n",
    "    \"embedding\":feature_embeddings,\n",
    "    \"target\":target,\n",
    "    \"paths\": paths,\n",
    "    \"classes\":labels\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "with open(f'./semantic_train.pickle', 'wb') as pickle_file:\n",
    "    pickle.dump(data_dict, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 6])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(prediction_columns, dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Maods\\.pyenv\\pyenv-win\\versions\\3.10.4\\lib\\site-packages\\rasterio\\__init__.py:317: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n",
      "WARNING:rasterio._env:CPLE_AppDefined in libpng: iCCP: known incorrect sRGB profile\n",
      "WARNING:rasterio._env:CPLE_AppDefined in libpng: iCCP: known incorrect sRGB profile\n",
      "WARNING:rasterio._env:CPLE_AppDefined in libpng: iCCP: known incorrect sRGB profile\n",
      "WARNING:rasterio._env:CPLE_AppDefined in libpng: iCCP: known incorrect sRGB profile\n",
      "WARNING:rasterio._env:CPLE_AppDefined in libpng: iCCP: known incorrect sRGB profile\n",
      "WARNING:rasterio._env:CPLE_AppDefined in libpng: iCCP: known incorrect sRGB profile\n",
      "WARNING:rasterio._env:CPLE_AppDefined in libpng: iCCP: known incorrect sRGB profile\n",
      "WARNING:rasterio._env:CPLE_AppDefined in libpng: iCCP: known incorrect sRGB profile\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = ImageDataLoader('../data/03_test')\n",
    "dataloader = DataLoader(data.dataset, batch_size=50, shuffle=False)\n",
    "\n",
    "target = []\n",
    "paths = []\n",
    "labels = []\n",
    "num_att = 7\n",
    "feature_embeddings = np.empty((0, num_att))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i, (x, y, path, label) in enumerate(dataloader):\n",
    "    x = x.to(device=device)\n",
    "    with torch.no_grad():\n",
    "        prediction_columns = []\n",
    "        for model in models:\n",
    "            model.eval()\n",
    "            output = model(x)\n",
    "            scores = torch.sigmoid(output)\n",
    "            prediction_columns.append(scores[:, 0].view(-1, 1))\n",
    "\n",
    "    prediction_matrix = torch.cat(prediction_columns, dim=1)\n",
    "    sclerosis_batch = np.array([sclerosis_predict(\n",
    "                                            p,\n",
    "                                            model_list_glo,\n",
    "                                            model_list_sle\n",
    "                                                  ) for p in path]).reshape(-1,1)    \n",
    "    emb_batch = np.hstack(( prediction_matrix.cpu().detach().numpy(), sclerosis_batch))\n",
    "    feature_embeddings = np.vstack((feature_embeddings, emb_batch))\n",
    "\n",
    "    target.extend(list(y.cpu().detach().numpy()))\n",
    "    paths.extend(slice_image_paths(path))\n",
    "    labels.extend(label)\n",
    "\n",
    "\n",
    "data_dict = {\n",
    "    \"model\": 'semantic_att',\n",
    "    \"embedding\":feature_embeddings,\n",
    "    \"target\":target,\n",
    "    \"paths\": paths,\n",
    "    \"classes\":labels\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "with open(f'./semantic_test.pickle', 'wb') as pickle_file:\n",
    "    pickle.dump(data_dict, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([47, 3, 224, 224])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99, 6)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_matrix.cpu().detach().numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sclerosis_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "renal-pathology-retrieval-P_udDvkW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
