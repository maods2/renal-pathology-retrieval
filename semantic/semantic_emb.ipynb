{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import sys\n",
    "\n",
    "sys.path.append('../embeddings/')\n",
    "sys.path.append('./embeddings/')\n",
    "sys.path.append('C:/Users/Maods/Downloads/terumo-seg-esclerose-main/terumo-seg-esclerose-main/terumo_seg_esclerose/')\n",
    "sys.path.append('..')\n",
    "\n",
    "from dataset import ImageDataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "from utils import slice_image_paths\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import torch\n",
    "import torchvision\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import numpy as np\n",
    "import re\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n",
    "# from terumo_seg_esclerose.cli import run_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Config (path: C:/Users/Maods/Downloads/terumo-seg-esclerose-main/terumo-seg-esclerose-main/configs/tiny/tiny-efficientnetb0-unet-pipeline.py): {'dataset_name': 'hubmap', 'path': './dist/datasets/hubmap/', 'cache': True, 'batch_size': 8, 'multiplier_bin': 4, 'binned_max': 20, 'output_pre': './dist/datasets/hubmap/patch/', 'split': 'train', 'dataset_pre_processing': {'shift_list': [0, 512], 'tile_size': 1024}, 'train_param': {'type': 'train_param', 'output_path': './dist/pretraining/', 'data_csv_path': './dist/datasets/hubmap/patch/data_balanced.csv', 'test_size': 0.3, 'random_state': 19, 'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225], 'batch_size': 12, 'shuffle': True, 'encoder_name': 'efficientnet-b0', 'encoder_weights': 'imagenet', 'classes': 1, 'activation': None, 'network_name': 'unet', 'loop_param': {'type': 'loop_param', 'filename_checkpoint': 'best_checkpoint.pth', 'cache_weight': None, 'result_csv': 'history.csv', 'max_lr': 0.001, 'epochs': 50, 'weight_decay': 1e-05, 'criterion_name': 'bce'}, 'transform_param': {'type': 'transform_param', 'img_size': 320}}, 'test_param': {'model_param': {'output_exp': {'sclerosis': 'C:/Users/Maods/Downloads/terumo-seg-esclerose-main/terumo-seg-esclerose-main/checkpoint/sclerosis', 'glomerulus': 'C:/Users/Maods/Downloads/terumo-seg-esclerose-main/terumo-seg-esclerose-main/checkpoint/glomerulus'}, 'filename_checkpoint': 'epoch_50.pth', 'encoder_name': 'efficientnet-b0', 'encoder_weights': 'imagenet', 'classes': 1, 'activation': None, 'network_name': 'unet'}, 'model': 'unet', 'input_resolution': 320, 'resolution': 1024, 'pad_size': 0, 'clf_threshold': 0.5, 'small_mask_threshold': 0, 'mask_threshold': 0.5, 'tta': 3, 'test_batch_size': 12, 'num_workers': 4}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import typer\n",
    "from terumo_seg_esclerose.utils.config import ConfigLoaded\n",
    "\n",
    "from terumo_seg_esclerose.predict.seg_glomerulus import predict as predict_glo\n",
    "from terumo_seg_esclerose.predict.seg_sclerosis import predict as predict_sle\n",
    "from mmengine.config import Config\n",
    "import numpy as np\n",
    "app = typer.Typer()\n",
    "\n",
    "path = 'C:/Users/Maods/Downloads/terumo-seg-esclerose-main/terumo-seg-esclerose-main/configs/tiny/tiny-efficientnetb0-unet-pipeline.py'\n",
    "ConfigLoaded().load_config(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_weights(model, model_path):\n",
    "    checkpoint = torch.load(model_path)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    return model\n",
    "\n",
    "def get_all_image_files(pathlib_root_folder):\n",
    "    img_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.gif']\n",
    "    img_regex = re.compile('|'.join(img_extensions), re.IGNORECASE)\n",
    "    image_files = [f for f in pathlib_root_folder.glob('**/*') if f.is_file() and img_regex.search(f.suffix)]\n",
    "    return image_files\n",
    "\n",
    "\n",
    "def predict(model, image):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        output = model(image.to(device))\n",
    "        scores = torch.sigmoid(output)\n",
    "        predictions = (scores>0.5).float()\n",
    "        _, pred = torch.min(predictions, 1)\n",
    "\n",
    "    return pred.item()\n",
    "\n",
    "def sclerosis_predict(image_path):\n",
    "    mask_glo = predict_glo(image_path)\n",
    "    mask_sle = predict_sle(image_path)\n",
    "\n",
    "    inter = np.logical_and(mask_glo > 0.5, mask_sle > 0.5)\n",
    "    p = np.sum(inter) / (np.sum(mask_glo > 0.5) + 0.00001)\n",
    "\n",
    "    # print(f\"Glomerulu with {p} sclerosis\")\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, net_version, num_classes, freeze: bool = False):\n",
    "        super(Net, self).__init__()\n",
    "        self.backbone = EfficientNet.from_pretrained('efficientnet-'+net_version)\n",
    "        self.backbone._fc = nn.Sequential(\n",
    "            nn.Linear(1280, num_classes),\n",
    "        )\n",
    "        if freeze:\n",
    "            # freeze backbone layers\n",
    "            for name, param in self.backbone.named_parameters():\n",
    "                if not name.startswith(\"_fc\"):\n",
    "                    param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m podoc_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./Podocytopathy-2024-02-10 21_20_29.072759-2_fold_min_loss_checkpoint.pth.tar\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      6\u001b[0m cresc_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./Crescent-2024-02-10 21_20_22.470548-1_fold_min_loss_checkpoint.pth.tar\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 9\u001b[0m hiper_model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mNet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mb0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhiper_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m membran_model \u001b[38;5;241m=\u001b[39m load_model_weights(Net(net_version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb0\u001b[39m\u001b[38;5;124m\"\u001b[39m, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device), membran_path)\n\u001b[0;32m     11\u001b[0m sclero_model \u001b[38;5;241m=\u001b[39m load_model_weights(Net(net_version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb0\u001b[39m\u001b[38;5;124m\"\u001b[39m, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device), sclero_path)\n",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m, in \u001b[0;36mload_model_weights\u001b[1;34m(model, model_path)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model_weights\u001b[39m(model, model_path):\n\u001b[1;32m----> 2\u001b[0m     checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_state_dict(checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate_dict\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\Maods\\.virtualenvs\\renal-pathology-retrieval-P_udDvkW\\lib\\site-packages\\torch\\serialization.py:1026\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1024\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1025\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1026\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _load(opened_zipfile,\n\u001b[0;32m   1027\u001b[0m                      map_location,\n\u001b[0;32m   1028\u001b[0m                      pickle_module,\n\u001b[0;32m   1029\u001b[0m                      overall_storage\u001b[38;5;241m=\u001b[39moverall_storage,\n\u001b[0;32m   1030\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[0;32m   1031\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n\u001b[0;32m   1032\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmmap can only be used with files saved with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1033\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`torch.save(_use_new_zipfile_serialization=True), \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1034\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease torch.save your checkpoint with this option in order to use mmap.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Maods\\.virtualenvs\\renal-pathology-retrieval-P_udDvkW\\lib\\site-packages\\torch\\serialization.py:1438\u001b[0m, in \u001b[0;36m_load\u001b[1;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1436\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[0;32m   1437\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[1;32m-> 1438\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1440\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[0;32m   1441\u001b[0m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_log_api_usage_metadata(\n\u001b[0;32m   1442\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.load.metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mserialization_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: zip_file\u001b[38;5;241m.\u001b[39mserialization_id()}\n\u001b[0;32m   1443\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Maods\\.virtualenvs\\renal-pathology-retrieval-P_udDvkW\\lib\\site-packages\\torch\\serialization.py:1408\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[1;34m(saved_id)\u001b[0m\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1407\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[1;32m-> 1408\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1410\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[1;32mc:\\Users\\Maods\\.virtualenvs\\renal-pathology-retrieval-P_udDvkW\\lib\\site-packages\\torch\\serialization.py:1382\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[1;34m(dtype, numel, key, location)\u001b[0m\n\u001b[0;32m   1377\u001b[0m         storage\u001b[38;5;241m.\u001b[39mbyteswap(dtype)\n\u001b[0;32m   1379\u001b[0m \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[0;32m   1380\u001b[0m \u001b[38;5;66;03m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[0;32m   1381\u001b[0m typed_storage \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39mTypedStorage(\n\u001b[1;32m-> 1382\u001b[0m     wrap_storage\u001b[38;5;241m=\u001b[39m\u001b[43mrestore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   1383\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   1384\u001b[0m     _internal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1386\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typed_storage\u001b[38;5;241m.\u001b[39m_data_ptr() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1387\u001b[0m     loaded_storages[key] \u001b[38;5;241m=\u001b[39m typed_storage\n",
      "File \u001b[1;32mc:\\Users\\Maods\\.virtualenvs\\renal-pathology-retrieval-P_udDvkW\\lib\\site-packages\\torch\\serialization.py:391\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[1;34m(storage, location)\u001b[0m\n\u001b[0;32m    389\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_restore_location\u001b[39m(storage, location):\n\u001b[0;32m    390\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[1;32m--> 391\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    392\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    393\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Maods\\.virtualenvs\\renal-pathology-retrieval-P_udDvkW\\lib\\site-packages\\torch\\serialization.py:266\u001b[0m, in \u001b[0;36m_cuda_deserialize\u001b[1;34m(obj, location)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_cuda_deserialize\u001b[39m(obj, location):\n\u001b[0;32m    265\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m location\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 266\u001b[0m         device \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_cuda_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    267\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_torch_load_uninitialized\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    268\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice(device):\n",
      "File \u001b[1;32mc:\\Users\\Maods\\.virtualenvs\\renal-pathology-retrieval-P_udDvkW\\lib\\site-packages\\torch\\serialization.py:250\u001b[0m, in \u001b[0;36mvalidate_cuda_device\u001b[1;34m(location)\u001b[0m\n\u001b[0;32m    247\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_get_device_index(location, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[1;32m--> 250\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAttempting to deserialize object on a CUDA \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    251\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice but torch.cuda.is_available() is False. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    252\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf you are running on a CPU-only machine, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    253\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    254\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto map your storages to the CPU.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    255\u001b[0m device_count \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count()\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m device_count:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "hiper_path = './Hypercellularity-2024-02-10 21_19_55.851047-3_fold_min_loss_checkpoint.pth.tar'\n",
    "membran_path = './Membranous-2024-02-10 21_20_09.125156-1_fold_min_loss_checkpoint.pth.tar'\n",
    "sclero_path = './Sclerosis-2024-02-10 21_20_15.760971-3_fold_min_loss_checkpoint.pth.tar'\n",
    "normal_path = './Normal-2024-02-10 21_20_02.347231-2_fold_min_loss_checkpoint.pth.tar'\n",
    "podoc_path = './Podocytopathy-2024-02-10 21_20_29.072759-2_fold_min_loss_checkpoint.pth.tar'\n",
    "cresc_path = './Crescent-2024-02-10 21_20_22.470548-1_fold_min_loss_checkpoint.pth.tar'\n",
    "\n",
    "\n",
    "hiper_model = load_model_weights(Net(net_version=\"b0\", num_classes=2).to(device), hiper_path)\n",
    "membran_model = load_model_weights(Net(net_version=\"b0\", num_classes=2).to(device), membran_path)\n",
    "sclero_model = load_model_weights(Net(net_version=\"b0\", num_classes=2).to(device), sclero_path)\n",
    "normal_model = load_model_weights(Net(net_version=\"b0\", num_classes=2).to(device), normal_path)\n",
    "podoc_model = load_model_weights(Net(net_version=\"b0\", num_classes=2).to(device), podoc_path)\n",
    "cresc_model = load_model_weights(Net(net_version=\"b0\", num_classes=2).to(device), cresc_path)\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "\n",
    "\n",
    "models = [hiper_model,membran_model,sclero_model,normal_model,podoc_model,cresc_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7769], device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# image = Image.open('C:/Users/Maods/Documents/Development/Mestrado/terumo/apps/terumo-model-binary-glomerulus-hypercellularity/data/raw/hipercellularity/AZAN/PSHIPERCELULARIDADE20200802-10.JPG')\n",
    "# image = Image.open('C:/Users/Maods/Documents/Development/Mestrado/terumo/apps/terumo-model-binary-glomerulus-hypercellularity/data/raw/crescentes/H_E/FIOCRUZ20190122 (6).jpg')\n",
    "# image = transform(image)\n",
    "# image = image.unsqueeze(0)\n",
    "# with torch.no_grad():\n",
    "#     cresc_model.eval()\n",
    "#     output = cresc_model(image.to(device))\n",
    "#     scores = torch.sigmoid(output)\n",
    "# scores[:, 0]\n",
    "# predictions = (scores>0.5).float()\n",
    "# predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ImageDataLoader('../data/02_data_split/train_data')\n",
    "dataloader = DataLoader(data.dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "target = []\n",
    "paths = []\n",
    "labels = []\n",
    "num_att = 6\n",
    "feature_embeddings = np.empty((0, num_att))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i, (x, y, path, label) in enumerate(dataloader):\n",
    "    x = x.to(device=device)\n",
    "    with torch.no_grad():\n",
    "        prediction_columns = []\n",
    "        for model in models:\n",
    "            model.eval()\n",
    "            output = model(x)\n",
    "            scores = torch.sigmoid(output)\n",
    "            prediction_columns.append(scores[:, 0].view(-1, 1))\n",
    "        \n",
    "\n",
    "    prediction_matrix = torch.cat(prediction_columns, dim=1)\n",
    "    feature_embeddings = np.vstack((feature_embeddings, prediction_matrix.cpu().detach().numpy()))\n",
    "\n",
    "    target.extend(list(y.cpu().detach().numpy()))\n",
    "    paths.extend(slice_image_paths(path))\n",
    "    labels.extend(label)\n",
    "\n",
    "\n",
    "data_dict = {\n",
    "    \"model\": 'semantic_att',\n",
    "    \"embedding\":feature_embeddings,\n",
    "    \"target\":target,\n",
    "    \"paths\": paths,\n",
    "    \"classes\":labels\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "with open(f'./semantic_train.pickle', 'wb') as pickle_file:\n",
    "    pickle.dump(data_dict, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = ImageDataLoader('../data/03_test')\n",
    "dataloader = DataLoader(data.dataset, batch_size=50, shuffle=False)\n",
    "\n",
    "target = []\n",
    "paths = []\n",
    "labels = []\n",
    "num_att = 6\n",
    "feature_embeddings = np.empty((0, num_att))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i, (x, y, path, label) in enumerate(dataloader):\n",
    "    x = x.to(device=device)\n",
    "    with torch.no_grad():\n",
    "        prediction_columns = []\n",
    "        for model in models:\n",
    "            model.eval()\n",
    "            output = model(x)\n",
    "            scores = torch.sigmoid(output)\n",
    "            prediction_columns.append(scores[:, 0].view(-1, 1))\n",
    "\n",
    "\n",
    "    prediction_matrix = torch.cat(prediction_columns, dim=1)\n",
    "    feature_embeddings = np.vstack((feature_embeddings, prediction_matrix.cpu().detach().numpy()))\n",
    "\n",
    "    target.extend(list(y.cpu().detach().numpy()))\n",
    "    paths.extend(slice_image_paths(path))\n",
    "    labels.extend(label)\n",
    "\n",
    "\n",
    "data_dict = {\n",
    "    \"model\": 'semantic_att',\n",
    "    \"embedding\":feature_embeddings,\n",
    "    \"target\":target,\n",
    "    \"paths\": paths,\n",
    "    \"classes\":labels\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "with open(f'./semantic_test.pickle', 'wb') as pickle_file:\n",
    "    pickle.dump(data_dict, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.21664597, 0.05527985, 0.0024234 , 0.01381866, 0.04079605,\n",
       "       0.95408595])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['03_test/crescentes/312969_3_En_20_Fig3_HTML.png',\n",
       " '03_test/crescentes/BtkTpI4CMAEee6d.jpg',\n",
       " '03_test/crescentes/Fig-3-The-histology-of-the-kidney-A-glomerulus-showing-accumulation-of-cells-and.png',\n",
       " '03_test/crescentes/Glomerulus-showing-crescentic-glomerulonephritis-due-to-pauci-immune-ANCA-associated_Q320.jpg',\n",
       " '03_test/crescentes/H-E-stains-showing-crescentic-glomerulonephritis-with-moderate-interstitial-inflammation.png',\n",
       " '03_test/crescentes/Rapidly_progressive_glomerulonephritis_type_3_high.jpg',\n",
       " '03_test/crescentes/cellular-crescent-glomerulus-quiz.jpg',\n",
       " '03_test/crescentes/ch523.fig3_.jpg',\n",
       " '03_test/crescentes/kidneyrpgnMurshed02.jpg',\n",
       " '03_test/crescentes/kidneyrpgnMurshed25.jpg',\n",
       " '03_test/crescentes/urn_cambridge.org_id_binary_20181009125204364-0075_9781107281981_61398fig7_3.png',\n",
       " '03_test/crescentes/urn_cambridge.org_id_binary_20181009125204364-0075_9781107281981_61398fig7_6.png',\n",
       " '03_test/hipercellularity/E7yBoUfwoEMqTSCkMhmm1w.jpg',\n",
       " '03_test/hipercellularity/Fig-4-copy-12.jpg',\n",
       " '03_test/hipercellularity/MPGN.jpg',\n",
       " '03_test/hipercellularity/P3.png',\n",
       " '03_test/hipercellularity/Post-streptococcal-glomerulonephritis.webp',\n",
       " '03_test/hipercellularity/RENAL084.jpg',\n",
       " '03_test/hipercellularity/casereports-2018-July-2018---F1.large.jpg',\n",
       " '03_test/hipercellularity/kidneymembranoprolifzhang02.jpg',\n",
       " '03_test/hipercellularity/kidneymembranoprolifzhang03.jpg',\n",
       " '03_test/hipercellularity/micro10.jpg',\n",
       " '03_test/hipercellularity/urn_cambridge.org_id_binary_20170125164512741-0116_9781139137201_02283fig31_11.png',\n",
       " '03_test/membranous/Glomerulus-of-a-young-man-with-membranous-glomerulonephritis-showing-the-characteristic.png',\n",
       " '03_test/membranous/Hole-and-Spike-Formation-in-Membranous-Glomerulopathy-on-Silver-Stain.webp',\n",
       " '03_test/membranous/J4gpH6SzDyRxDg38555-.webp',\n",
       " '03_test/membranous/Membranous_GN_3.jpg',\n",
       " '03_test/membranous/RENAL088.jpg',\n",
       " '03_test/membranous/ch2625.fig1_.jpg',\n",
       " '03_test/membranous/membranous.jpg',\n",
       " '03_test/membranous/urn_cambridge.org_id_binary_20181009125204364-0075_9781107281981_61398fig4_58.png',\n",
       " '03_test/membranous/urn_cambridge.org_id_binary_20181009125204364-0075_9781107281981_61398fig4_59.png',\n",
       " '03_test/normal/2023PC0538 (14).jpg',\n",
       " '03_test/normal/2023PC0538 (25) - co╠üpia.jpg',\n",
       " '03_test/normal/2023PC0538 (40).jpg',\n",
       " '03_test/normal/2023PC0538 (6).jpg',\n",
       " '03_test/normal/2023PC0594 (17).jpg',\n",
       " '03_test/normal/2023PC0594 (3).jpg',\n",
       " '03_test/normal/2023PC0599 (10).jpg',\n",
       " '03_test/normal/2023PC0599 (14).jpg',\n",
       " '03_test/normal/IMG_0610.JPG',\n",
       " '03_test/normal/IMG_0611.JPG',\n",
       " '03_test/normal/IMG_0623.JPG',\n",
       " '03_test/normal/IMG_0624.JPG',\n",
       " '03_test/normal/IMG_0625 (1).JPG',\n",
       " '03_test/normal/IMG_0629.JPG',\n",
       " '03_test/normal/IMG_0630.JPG']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "renal-pathology-retrieval-P_udDvkW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
